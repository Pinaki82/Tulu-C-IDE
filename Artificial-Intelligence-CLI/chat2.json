{
  // CMD in Admin mode
  // mklink /J "C:\Users\AppuRaja\AppData\Local\nomic.ai\GPT4All\" "N:\GPT4All"
  // https://gpt4all.io/
  // https://github.com/kuvaus/LlamaGPTJ-chat
  // chat-windows-latest-avx2.exe -j %userprofile%\gpt4all\chat.json
  // Or,
  // chat-windows-latest-avx2.exe -m "N:\GPT4All\ggml-mpt-7b-chat.bin" -t 4

  //NOTE: Tested on code generation only
  //
  //"model": "N:\GPT4All\ggml-gpt4all-j-v1.3-groovy.bin",
  //"model": "N:\GPT4All\ggml-mpt-7b-chat.bin",
  //"model": "N:\GPT4All\ggml-nous-gpt4-vicuna-13b.bin",
  //"model": "N:\GPT4All\ggml-vicuna-7b-1.1-q4_2.bin",
  //      //censored
  //"model": "N:\GPT4All\ggml-wizard-13b-uncensored.bin",
  //"model": "N:\GPT4All\ggml-wizardLM-7B.q4_2.bin",

  "load_json": "N:\GPT4All\gpt4all\chat.json"
  "load_log":  "N:\GPT4All\chatlog.log",
  "save_log":  "N:\GPT4All\chatlog.log",
  "n_predict": 200,
  "top_p": 0.95,
  "top_k": 40,
  "temp": 0.28,
  "batch_size": 0.9,
  "repeat_penalty": 1.1,
  "repeat_last_n": 64,
  "n_batch": 9,
  "threads": 4,
  "model": "N:\GPT4All\ggml-mpt-7b-chat.bin",
  "no-interactive": "false"
}
